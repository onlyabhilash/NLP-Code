{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onlyabhilash/NLP-Code/blob/main/part-5/05_BERT_SNIPS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqXsulG-foOX"
      },
      "source": [
        "In this notebook we demonstrate using BERT for the task of slot filling on the SNIPS dataset. The data can be found in folder for Ch6 in this repo.<br>\n",
        "This notebook requires a GPU to get setup. We suggest you to run this on your local machine only if you have a GPU setup or else you can use google colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMqpe5rnf1op"
      },
      "source": [
        "### Importing\n",
        "Importing and installing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gety72pIhW7j",
        "outputId": "7b228da8-4da2-4919-eccd-3f00eb974cbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting pytorch-pretrained-bert==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/68/84de54aea460eb5b2e90bf47a429aacc1ce97ff052ec40874ea38ae2331d/pytorch_pretrained_bert-0.4.0-py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (2.23.0)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/e1/1b164502f455035def771ec7a31f705351b7f953695d57ce26219aaf21a9/boto3-1.17.90-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.19.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.8.1+cu101)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (1.24.3)\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.8MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.90\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/ac/617d3ac25ea905279deb06edd82d6c19ca272006d6dcf232b837b75c3dde/botocore-1.20.90-py2.py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 46.2MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert==0.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.90->boto3->pytorch-pretrained-bert==0.4.0) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.90->boto3->pytorch-pretrained-bert==0.4.0) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.20.90 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.17.90 botocore-1.20.90 jmespath-0.10.0 pytorch-pretrained-bert-0.4.0 s3transfer-0.4.2\n",
            "Collecting seqeval==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.12) (1.19.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /tensorflow-1.15.2/python3.7 (from seqeval==0.0.12) (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from Keras>=2.2.4->seqeval==0.0.12) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.12) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.12) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.12) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.12) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.12) (3.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->Keras>=2.2.4->seqeval==0.0.12) (1.5.2)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp37-none-any.whl size=7436 sha256=cb9b93bd09bfd6e7304259f8032d02ae36c7e7c5dd3e23ece354e0360c611bb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n",
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "% tensorflow_version 1.x \n",
        "\n",
        "#Installing required packages \n",
        "!pip install pytorch-pretrained-bert==0.4.0\n",
        "!pip install seqeval==0.0.12\n",
        "\n",
        "#importing packages for string processing,dataframe handling, array manipulations, etc\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "#importing all the pytorch packages\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam\n",
        "\n",
        "#importing additonal packages to aid preprocessing of data\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#importing packages to calculate the f1_score of our model\n",
        "from seqeval.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuXoMTpfhcLu"
      },
      "source": [
        "Uploading the file into google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "QrdCfa9D7sDx",
        "outputId": "2c61bfc8-068f-49fd-ae99-c292c864da12"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5289e7bf-63e7-4251-8ff3-10b59527db3a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5289e7bf-63e7-4251-8ff3-10b59527db3a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving train_PlayMusic_full.json to train_PlayMusic_full.json\n",
            "Saving validate_PlayMusic.json to validate_PlayMusic.json\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    train_loc = \"train_PlayMusic_full.json\"\n",
        "    test_loc = \"validate_PlayMusic.json\"\n",
        "except ModuleNotFoundError:\n",
        "    train_loc = \"Data/snips/train_PlayMusic_full.json\"\n",
        "    test_loc = \"Data/snips/validate_PlayMusic.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nJiVB2dhfP4"
      },
      "source": [
        "Readind the json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ejxRP-V7xE1"
      },
      "outputs": [],
      "source": [
        "train_file = json.load(open(train_loc, encoding= \"iso-8859-2\"))\n",
        "test_file = json.load(open(test_loc, encoding= \"iso-8859-2\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImDVF-qOhp-V"
      },
      "source": [
        "### Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJ8HlEyr8bs5"
      },
      "outputs": [],
      "source": [
        "train_datafile = [i[\"data\"] for i in train_file[\"PlayMusic\"]]\n",
        "test_datafile = [i[\"data\"] for i in test_file[\"PlayMusic\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mYinws6hjUj"
      },
      "source": [
        "Helper functions to process the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5fmDAoZ8dx6"
      },
      "outputs": [],
      "source": [
        "def convert_data(datalist):\n",
        "    output = []\n",
        "    for data in datalist:\n",
        "        sent = []\n",
        "        pos = []\n",
        "        for phrase in data:\n",
        "            words = phrase[\"text\"].strip().split(\" \")\n",
        "            while \"\" in words:\n",
        "                words.remove(\"\")\n",
        "            if \"entity\" in phrase.keys():\n",
        "                label = phrase[\"entity\"]\n",
        "                labels = [label+\"-{}\".format(i+1) for i in range(len(words))]\n",
        "            else:\n",
        "                labels = [\"O\"] * len(words)\n",
        "            sent.extend(words)\n",
        "            pos.extend(labels)\n",
        "        output.append([sent, pos])\n",
        "        # print(sent)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "UkvdSDU08ilm",
        "outputId": "8c26ef72-c04f-4401-b755-797c6f83adad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[I, need, to, hear, the, song, Aspro, Mavro, f...</td>\n",
              "      <td>[O, O, O, O, O, music_item-1, track-1, track-2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[play, Yo, Ho, from, the, new, york, pops, on,...</td>\n",
              "      <td>[O, track-1, track-2, O, artist-1, artist-2, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Play, some, seventies, music, by, Janne, Puur...</td>\n",
              "      <td>[O, O, year-1, O, O, artist-1, artist-2, O, se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[play, the, MĂşsica, Da, SĂŠrie, De, Filmes, O...</td>\n",
              "      <td>[O, O, album-1, album-2, album-3, album-4, alb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Play, Magic, Sam, from, the, thirties]</td>\n",
              "      <td>[O, artist-1, artist-2, O, O, year-1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence                                              label\n",
              "0  [I, need, to, hear, the, song, Aspro, Mavro, f...  [O, O, O, O, O, music_item-1, track-1, track-2...\n",
              "1  [play, Yo, Ho, from, the, new, york, pops, on,...  [O, track-1, track-2, O, artist-1, artist-2, a...\n",
              "2  [Play, some, seventies, music, by, Janne, Puur...  [O, O, year-1, O, O, artist-1, artist-2, O, se...\n",
              "3  [play, the, MĂşsica, Da, SĂŠrie, De, Filmes, O...  [O, O, album-1, album-2, album-3, album-4, alb...\n",
              "4            [Play, Magic, Sam, from, the, thirties]              [O, artist-1, artist-2, O, O, year-1]"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data = convert_data(train_datafile)\n",
        "test_data = convert_data(test_datafile)\n",
        "\n",
        "df_train = pd.DataFrame(train_data,columns=['sentence','label'])\n",
        "df_test = pd.DataFrame(test_data,columns=['sentence','label'])\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKiCnohqhzf2"
      },
      "source": [
        "We need to now get the unique labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybF5FSMP8kn8",
        "outputId": "0a1d8143-0e65-48f5-d3f3-21d4f2857c72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['genre-4',\n",
              " 'track-7',\n",
              " 'album-2',\n",
              " 'playlist-4',\n",
              " 'artist-3',\n",
              " 'artist-5',\n",
              " 'service-1',\n",
              " 'artist-4',\n",
              " 'playlist-3',\n",
              " 'track-4']"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence = list(df_train['sentence'])+list(df_test['sentence'])#sentences in both test and train\n",
        "label  = list(df_train['label'])+list(df_test['label'])#label in both test and train\n",
        "\n",
        "unique_labels=[]\n",
        "for i in label:\n",
        "    unique_labels += i\n",
        "\n",
        "labels = unique_labels # all the labels\n",
        "unique_labels = set(unique_labels)#set of all the unique labels\n",
        "\n",
        "list(unique_labels)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYjw7Hzgk0Q4",
        "outputId": "ec556f3e-db9a-49bd-9fee-7492060987f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['I',\n",
              "  'need',\n",
              "  'to',\n",
              "  'hear',\n",
              "  'the',\n",
              "  'song',\n",
              "  'Aspro',\n",
              "  'Mavro',\n",
              "  'from',\n",
              "  'Bill',\n",
              "  'Szymczyk',\n",
              "  'on',\n",
              "  'Youtube'],\n",
              " ['play', 'Yo', 'Ho', 'from', 'the', 'new', 'york', 'pops', 'on', 'Youtube']]"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3sMXj_ukmOh"
      },
      "source": [
        "We need to join all the tokens into a single sentence. We will use the untokenize function in token_utils from [this](https://github.com/commonsense/metanl/blob/master/metanl/token_utils.py) github repo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjoeGhClj78E"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def untokenize(words):\n",
        "    \"\"\"\n",
        "    Untokenizing a text undoes the tokenizing operation, restoring\n",
        "    punctuation and spaces to the places that people expect them to be.\n",
        "    Ideally, `untokenize(tokenize(text))` should be identical to `text`,\n",
        "    except for line breaks.\n",
        "    \"\"\"\n",
        "    text = ' '.join(words)\n",
        "    step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .',  '...')\n",
        "    step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
        "    step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
        "    step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
        "    step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
        "         \"can not\", \"cannot\")\n",
        "    step6 = step5.replace(\" ` \", \" '\")\n",
        "    return step6.strip()\n",
        "\n",
        "sentences_untokenized = [untokenize(i) for i in sentence]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rNxrLnae2gef",
        "outputId": "12445b63-82ff-44f8-a017-97ad343c0a36"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I need to hear the song Aspro Mavro from Bill Szymczyk on Youtube'"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences_untokenized[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXieM-1p-LGC",
        "outputId": "8e772414-86d7-49f7-c115-46dc2cb91c58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 305110.74B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['[CLS]', 'i', 'need', 'to', 'hear', 'the', 'song', 'as', '##pro', 'ma', '##vr', '##o', 'from', 'bill', 's', '##zy', '##mc', '##zy', '##k', 'on', 'youtube', '[SEP]'], ['[CLS]', 'play', 'yo', 'ho', 'from', 'the', 'new', 'york', 'pops', 'on', 'youtube', '[SEP]']]\n"
          ]
        }
      ],
      "source": [
        "#setting up pytorch to use GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "#prescribed configurations that we need to fix for BERT.\n",
        "MAX_LEN = 75\n",
        "bs = 32\n",
        "\n",
        "#BERT's implementation comes with a pretained tokenizer and a defined vocabulary\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "#tokenizing the text\n",
        "tokenized_texts = [[\"[CLS]\"] +tokenizer.tokenize(sent)+ [\"[SEP]\"] for sent in sentences_untokenized]\n",
        "print(tokenized_texts[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5o3olMNDNTO",
        "outputId": "b3640c5c-4552-478a-dece-cf4ea8d413f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15292,)"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(labels).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTMARnfdDSFN",
        "outputId": "f389d9d4-036e-4bbb-b485-ccdee82761d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['genre-4',\n",
              " 'track-7',\n",
              " 'album-2',\n",
              " 'playlist-4',\n",
              " 'artist-3',\n",
              " 'artist-5',\n",
              " 'service-1',\n",
              " 'artist-4',\n",
              " 'playlist-3',\n",
              " 'track-4']"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#pre-processing the labels\n",
        "tags_vals = list(unique_labels)\n",
        "tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
        "tags_vals[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8OoO45gDg8b"
      },
      "outputs": [],
      "source": [
        "#cutting and padding the tokens and labels to our desired length\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in label],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"O\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwznylB1DiiH"
      },
      "outputs": [],
      "source": [
        "#BERT supports something called attention masks\n",
        "#Tells the model which tokens should be attended to, and which should not.\n",
        "#learn more about this at https://huggingface.co/transformers/glossary.html#attention-mask\n",
        "\n",
        "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gosRXgG-D50X"
      },
      "outputs": [],
      "source": [
        "#split the dataset to use 10% to validate the model.\n",
        "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPLqDFjQFTcq"
      },
      "outputs": [],
      "source": [
        "#pytorch requires inouts to be in the form of torch tensors\n",
        "#Learn more about torch tensors at https://pytorch.org/docs/stable/tensors.html\n",
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR6TON_nFVM0"
      },
      "outputs": [],
      "source": [
        "#Define the Data Loaders\n",
        "#Shuffle the data at training time\n",
        "#Pass them sequentially during test time\n",
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g1e4W2TFWcN",
        "outputId": "b7bbb06f-e9db-4bb8-8191-732b97cad01d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:33<00:00, 12025777.98B/s]\n"
          ]
        }
      ],
      "source": [
        "#Fine-Tuning BERT\n",
        "# BertForTokenClassification class of pytorch-pretrained-bert package provides  for token-level predictions\n",
        "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxORw8EmFYcr",
        "outputId": "0e0b0789-32c0-4119-9b49-dab73b0878af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=42, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Passing model parameters into GPU\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "else:\n",
        "    model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy_qc5ooFaXv"
      },
      "outputs": [],
      "source": [
        "#Before starting fine tuing we need to add the optimizer. Generally Adam is used\n",
        "#weight_decay is added as regularization to the main weight matrices\n",
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmDcDaHcFdDz"
      },
      "outputs": [],
      "source": [
        "#accuracy\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iDUGLz9FeeH",
        "outputId": "4056c84c-1fe9-422d-9f7c-885536ee9762"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.4888806909322739\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            "Epoch:  20%|██        | 1/5 [00:20<01:21, 20.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.1323928598846708\n",
            "Validation Accuracy: 0.9716203703703704\n",
            "F1-Score: 0.6049495875343721\n",
            "Train loss: 0.11743840376536051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            "Epoch:  40%|████      | 2/5 [00:40<01:00, 20.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.08609402924776077\n",
            "Validation Accuracy: 0.9785383597883597\n",
            "F1-Score: 0.7006039689387402\n",
            "Train loss: 0.07893053752680619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            "Epoch:  60%|██████    | 3/5 [00:59<00:40, 20.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.06485400402120181\n",
            "Validation Accuracy: 0.9827447089947091\n",
            "F1-Score: 0.7598627787307033\n",
            "Train loss: 0.0569656090810895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            "Epoch:  80%|████████  | 4/5 [01:19<00:20, 20.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.05173933506011963\n",
            "Validation Accuracy: 0.9856547619047619\n",
            "F1-Score: 0.8149920255183413\n",
            "Train loss: 0.043735417909920214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 5/5 [01:39<00:00, 19.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.04572244201387678\n",
            "Validation Accuracy: 0.9873544973544973\n",
            "F1-Score: 0.8239936858721388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Add the epoch number. \n",
        "#Link to the paper https://arxiv.org/abs/1810.04805\n",
        "epochs = 5\n",
        "max_grad_norm = 1.0\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "train_loss_set = []\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    # TRAIN loop\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # forward pass\n",
        "        loss = model(b_input_ids, token_type_ids=None,\n",
        "                     attention_mask=b_input_mask, labels=b_labels)\n",
        "        train_loss_set.append(loss.item())\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        model.zero_grad()\n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "\n",
        "\n",
        "    # VALIDATION on validation set\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in valid_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
        "                                  attention_mask=b_input_mask, labels=b_labels)\n",
        "            logits = model(b_input_ids, token_type_ids=None,\n",
        "                           attention_mask=b_input_mask)\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.append(label_ids)\n",
        "        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        \n",
        "        nb_eval_examples += b_input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "    eval_loss = eval_loss/nb_eval_steps\n",
        "    print(\"Validation loss: {}\".format(eval_loss))\n",
        "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "    pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
        "    valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
        "    print(\"F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "ksirPywSFgdO",
        "outputId": "a7c590ac-1641-4129-b296-0a03c2be35c3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# plot training performance\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "05_BERT_SNIPS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}